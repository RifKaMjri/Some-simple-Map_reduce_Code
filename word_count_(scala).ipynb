{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnr6VwPBHLRO",
        "outputId": "2338cf40-c792-4492-b674-e3a1214dd3ba"
      },
      "outputs": [
        {
          "ename": "org.apache.hadoop.mapred.FileAlreadyExistsException",
          "evalue": " Output directory hdfs://localhost:9000/refka11/resultat already exists",
          "output_type": "error",
          "traceback": [
            "org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/refka11/resultat already exists",
            "  at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)",
            "  at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)",
            "  at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
            "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
            "  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
            "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
            "  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)",
            "  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
            "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
            "  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)",
            "  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)",
            "  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)",
            "  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
            "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
            "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)",
            "  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)",
            "  ... 37 elided",
            ""
          ]
        }
      ],
      "source": [
        "val textFile = sc.textFile(\"hdfs:/refka11/texte\")\n",
        "val counts = textFile.flatMap(line => line.split(\" \"))\n",
        "                 .map(word => (word, 1))\n",
        "                 .reduceByKey(_ + _)\n",
        "counts.saveAsTextFile(\"hdfs:/refka11/resultat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXguchMpHLRV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spylon-kernel",
      "language": "scala",
      "name": "spylon-kernel"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "help_links": [
        {
          "text": "MetaKernel Magics",
          "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
        }
      ],
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala",
      "version": "0.4.1"
    },
    "colab": {
      "name": "word count (scala).ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}